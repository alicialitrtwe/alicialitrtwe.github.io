[{"authors":["admin"],"categories":null,"content":"My research goal is to contribute to our understanding of the elusive questions lying at the intersection of physics, neuroscience, and philosophy: how do robust, adaptive representations of the world emerge from the collective dynamics of ensembles of interconnected neurons? How can we rigorously explain the emergence of high-level semantic structures from low-level syntaxes? Specifially, I am interested in eluciating fundamental computational principles of neural circuits with quantitative tools from dynamical systems, machine learning, and statistics.\nI am a Chinese citizen and an American permanent resident, born and raised in Beijing. When I am not doing research in theoretical neuroscience, I enjoy camping and hiking in beatiful mountainous areas, practicing Ballet, and reading on philosphy.\n","date":1549324800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1567641600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://alicialitrtwe.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"My research goal is to contribute to our understanding of the elusive questions lying at the intersection of physics, neuroscience, and philosophy: how do robust, adaptive representations of the world emerge from the collective dynamics of ensembles of interconnected neurons? How can we rigorously explain the emergence of high-level semantic structures from low-level syntaxes? Specifially, I am interested in eluciating fundamental computational principles of neural circuits with quantitative tools from dynamical systems, machine learning, and statistics.","tags":null,"title":"Alicia Zeng","type":"authors"},{"authors":null,"categories":null,"content":"Flexibility This feature can be used for publishing content such as:\n Online courses Project or software documentation Tutorials  The courses folder may be renamed. For example, we can rename it to docs for software/project documentation or tutorials for creating an online course.\nDelete tutorials To remove these pages, delete the courses folder and see below to delete the associated menu link.\nUpdate site menu After renaming or deleting the courses folder, you may wish to update any [[main]] menu links to it by editing your menu configuration at config/_default/menus.toml.\nFor example, if you delete this folder, you can remove the following from your menu configuration:\n[[main]] name = \u0026quot;Courses\u0026quot; url = \u0026quot;courses/\u0026quot; weight = 50  Or, if you are creating a software documentation site, you can rename the courses folder to docs and update the associated Courses menu configuration to:\n[[main]] name = \u0026quot;Docs\u0026quot; url = \u0026quot;docs/\u0026quot; weight = 50  Update the docs menu If you use the docs layout, note that the name of the menu in the front matter should be in the form [menu.X] where X is the folder name. Hence, if you rename the courses/example/ folder, you should also rename the menu definitions in the front matter of files within courses/example/ from [menu.example] to [menu.\u0026lt;NewFolderName\u0026gt;].\n","date":1536451200,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1536451200,"objectID":"59c3ce8e202293146a8a934d37a4070b","permalink":"https://alicialitrtwe.github.io/courses/example/","publishdate":"2018-09-09T00:00:00Z","relpermalink":"/courses/example/","section":"courses","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"Overview","type":"docs"},{"authors":null,"categories":null,"content":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 2 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"74533bae41439377bd30f645c4677a27","permalink":"https://alicialitrtwe.github.io/courses/example/example1/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example1/","section":"courses","summary":"In this tutorial, I'll share my top 10 tips for getting started with Academic:\nTip 1 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim.","tags":null,"title":"Example Page 1","type":"docs"},{"authors":null,"categories":null,"content":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\nTip 4 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557010800,"objectID":"1c2b5a11257c768c90d5050637d77d6a","permalink":"https://alicialitrtwe.github.io/courses/example/example2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/courses/example/example2/","section":"courses","summary":"Here are some more tips for getting started with Academic:\nTip 3 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus.","tags":null,"title":"Example Page 2","type":"docs"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic's Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"https://alicialitrtwe.github.io/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head()  Math Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $$...$$.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$  renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $$\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2$$ renders as $$\\left |\\nabla F(\\mathbf{x}{n}) - \\nabla F(\\mathbf{x}{n-1}) \\right |^2$$ .\nExample multi-line math using the \\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$  renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD; A--\u0026gt;B; A--\u0026gt;C; B--\u0026gt;D; C--\u0026gt;D; ```  renders as\ngraph TD; A--\u0026gt;B; A--\u0026gt;C; B--\u0026gt;D; C--\u0026gt;D;  An example sequence diagram:\n```mermaid sequenceDiagram participant Alice participant Bob Alice-\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts \u0026lt;br/\u0026gt;prevail... John--\u0026gt;Alice: Great! John-\u0026gt;Bob: How about you? Bob--\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram participant Alice participant Bob Alice-\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts \u0026lt;br/\u0026gt;prevail... John--\u0026gt;Alice: Great! John-\u0026gt;Bob: How about you? Bob--\u0026gt;John: Jolly good!  An example Gantt diagram:\n```mermaid gantt dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d another task : 24d ```  renders as\ngantt dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :after a1 , 20d section Another Task in sec :2014-01-12 , 12d another task : 24d  Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else  renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell |  renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Asides Academic supports a shortcode for asides, also referred to as notices, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}}  renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Did you find this page helpful? Consider sharing it ðŸ™Œ ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"07e02bccc368a192a0c76c44918396c3","permalink":"https://alicialitrtwe.github.io/post/writing-technical-content/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/writing-technical-content/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you'll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":null,"categories":null,"content":"This ongoing project involves analyzing multi-electrode array recordings of retinal responses. Specifically, Iâ€™m interested in using flexible poisson models to discern how variance reflects uncertainty in stimulus perception. This analysis aims to unveil neural computations that cannot be understood from measures of average firing rate alone.\n","date":1556323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556323200,"objectID":"350b37d9ee638990a27d44aacb533afe","permalink":"https://alicialitrtwe.github.io/project/project2retinal/","publishdate":"2019-04-27T00:00:00Z","relpermalink":"/project/project2retinal/","section":"project","summary":"Applying modulated Poisson models to retinal adaptation with multi-electrode array data","tags":["Visual"],"title":"Sensory Uncertainty","type":"project"},{"authors":["Xiao  Zeng and Armstrong","Eve Armstrong","Vijay Balasubramanian"],"categories":null,"content":"","date":1551830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551830400,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"https://alicialitrtwe.github.io/publication/conference-paper/","publishdate":"2019-03-06T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Songbird vocal production is a complex nonlinear phenomenon. However, acoustic studies of bird vocalization have mostly been based on linear spectral analysis. Such analysis methods necessarily fail to capture the information content of song, and for that reason are not effective probes of the means by which songbirds communicate. We present a novel approach to the analysis and classification of songbird vocalization using nonlinear time series analysis techniques. Time-delay embedding is used to construct a new coordinate system in which to view the song time series. The number of coordinates required to unfold the dynamics represents the dimensionality of a new geometric space, wherein the song's attractor can be visualized. We show that the reconstructed phase space representation of bird vocalization can reveal information that is absent in traditional linear approaches.","tags":["Songbirds"],"title":"A Nonlinear Dynamical System Approach to Bird Song Analysis","type":"publication"},{"authors":["Alicia Zeng"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png')  print(\u0026quot;Welcome to Academic!\u0026quot;)  Welcome to Academic!  Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb  The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... ---  Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post's folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=.  Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"6e929dc84ed3ef80467b02e64cd2ed64","permalink":"https://alicialitrtwe.github.io/post/jupyter/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/jupyter/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Display Jupyter Notebooks with Academic","type":"post"},{"authors":[],"categories":[],"content":"Welcome to Slides Academic\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://alicialitrtwe.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"This project applying nonlinear dynamical systems techniques to characterize the mechanics of zebra finch song production. I combined topological data analysis with machine learning to show that the geometries of the reconstructed state-spaces of bird song recordings contain useful information about birds\u0026rsquo; individual identities.\n","date":1524787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1524787200,"objectID":"1abcad2876233e6bfaeffe29f2e44e34","permalink":"https://alicialitrtwe.github.io/project/project1songbirds/","publishdate":"2018-04-27T00:00:00Z","relpermalink":"/project/project1songbirds/","section":"project","summary":"A Topological Approach to Extract Dynamical Information from Bird Vocalizations","tags":["Auditory"],"title":"Bird Vocalizations","type":"project"},{"authors":["Alicia Zeng"],"categories":[],"content":"%matplotlib inline  import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from ipywidgets import interactive from ipywidgets import FloatProgress from IPython.display import display import scipy.spatial as ss import scipy.stats as sst from scipy.special import digamma,gamma from math import log, pi, exp  0. Generate a standard chaotic system for sanity test I am using a 3D lorenz attractor to check whether the code works or not before plugging real-world data. You can test out other chaotic systems simply by changing the ODE function below.\n# Define a function for generating time-seies data given ODEs def solve_ODE(time, ODE, state, parameters, dt=0.01): trajectory = np.zeros([int(time/dt), state.shape[0]]) # Define the fourth-order Runge-Kutta method def rk4(ODE, state, parameters, dt): k1 = dt * ODE(state, parameters) k2 = dt * ODE(state + 0.5 * k1, parameters) k3 = dt * ODE(state + 0.5 * k2, parameters) k4 = dt * ODE(state + k3, parameters) return state + (k1 + 2 * k2 + 2 * k3 + k4) / 6 for i in range(int(time/dt)): state = rk4(ODE, state, parameters,dt) trajectory[i,:] = state return trajectory # Define ODEs for Lorenz Attractor def lorenz_ode(state, parameters): x, y, z = state sigma, beta, rho = parameters return np.array([sigma * (y - x), x * (rho - z) - y, x * y - beta * z]) # Now putting it together, define a function for generating lorenz systems given initial state and parameters def lorenz(time, x0, y0, z0, sigma, beta, rho): state = np.array([x0,y0,z0]) parameters = np.array([sigma, beta, rho]) trajectory = solve_ODE(time, lorenz_ode, state, parameters) fig = plt.figure() axe = fig.gca(projection='3d') x, y, z = trajectory[:,0],trajectory[:,1],trajectory[:,2] lines = axe.plot(x, y, z, lw=0.5) plt.show() return trajectory  lorenz_trajectory = lorenz(2**5, -8.0, 9.0, 20.0, 10.0, 8/3.0, 28.0)  You can play with the parameters and the initial inputs here (or ignore it, this is just me learning to use the interactive widget):\n%matplotlib inline w = interactive(lorenz, time=(0,2**5), x0=-8, y0=9, z0=20, sigma=10, beta=4, rho=30) display(w)  1. Select the appropriate time delay for state space reconstruction We use time lagged variables to form coordinates for the reconstructed phase space. Our goal is to identify a delayed measure which would give us as much new information about the evolution of the system as possible. Fraser proposes a good delay would be when the mutual information between $s(t)$ and $s(t+T)$ reaches its first local minimum http://chaos.ph.utexas.edu/manuscripts/1064949034.pdf.\n1.1 Mutual information estimator First we need to build a mutual information estimator. There are numerous methods aimming at correcting the bias which would arises from naively pluging in frequency distributions of the samples as the underlying probabiliy distribution Here I choose Kraskov's K-nearest-neighbor estimator as it has been shown to be stable and less affected by parameters especially for time series from nonlinear dynamical systems https://arxiv.org/pdf/cond-mat/0305641.pdf; https://arxiv.org/pdf/0809.2149.pdf.\nBelow is the code I wrote using the second algorithm proposed by the Kraskov paper. I compared my code with several versions of knn mi estimators on github. However, they are all slightly different from each other and give slightly different results. In my opinion the codes which I have viewed on github all make some mistakes here and there, but I cannot say mine is mistake-proof either. I have to check more, but for now the codes would suffice for my purpose, as the difference in the results is negligible.\nFirst, for one dimensional data:\ndef MI_knn_1D(x,y, k=3, base=2): # Input functions: # X, Y: array_like, shape (n,). Both inputs are n samples of data points with one feature # k: the number of nearest neighbour # base: log base # output function: # MI_estimate: Mutual Information estimate using the second algorithm proposed by the Kraskov paper # Kraskov, Stogbauer, and Grassberger, \u0026quot;Estimating mutual information\u0026quot;, Physical review E 69, no. 6 (2004): 066138. N = len(x) # sample size nx = np.zeros(N) ny = np.zeros(N) x = np.expand_dims(x, axis=1) y = np.expand_dims(y, axis=1) x_y = np.concatenate((x,y),axis=1) tree_xy = ss.cKDTree(x_y) tree_x = ss.cKDTree(x) tree_y = ss.cKDTree(y) for i in range(N): knn_idx = tree_xy.query(x_y[i],k+1,p=float('inf'))[1][k] knn = tree_xy.data[knn_idx] epsX = np.absolute(knn[0]-x[i]) epsY = np.absolute(knn[1]-y[i]) nx[i] = len(tree_x.query_ball_point(x[i], epsX, p=2)) ny[i] = len(tree_y.query_ball_point(y[i], epsY, p=2)) MI_estimate = (digamma(k) - 1/float(k) - (sum(list(map(digamma, nx)) + list(map(digamma, ny))) / N)+ digamma(N) ) / np.log(base) return MI_estimate  def MI_plugin(x, y, base = 2): bins = np.ceil(np.log2(len(x)))+1 histgram, x_edges, y_edges = np.histogram2d(x, y, bins = bins) Pxy = histgram / float(np.sum(histgram)) Px = np.sum(Pxy, axis=1) # Get the marginal probability of x by summing over y Py = np.sum(Pxy, axis=0) # Get the marginal probability of y by summing over x PxPy = Px[:, None] * Py[None, :] non_zero = Pxy \u0026gt; 0 # Only non-zero Pxy terms contribute to the sum return np.sum(Pxy[non_zero] * np.log2(Pxy[non_zero] / PxPy[non_zero]))  1.2 Plot MI against time delay We find mutual information as a function of time delay, and locate the time delay when mutual information reaches it first minimum.\ndef MI_tau(time_series, dt, code=MI_knn_1D,tau_number=40): # Input functions: # time_series: shape (n_samples, n_features). n_samples is the number of points in the time series, # and n_features is the dimension of the parameter space.array_like, shape (n,m). The time series to be unfolded # code: MI_knn_1D or MI_knn_multiD. For one dimensional data, both codes give same result, but MI_knn_1D runs much faster, # becuase it uses KDTree to find nearest neighbor. # tau_number: the number of time delays for which to estimate mutual information # dt: the time duration between two sample points in the time series # Output functions: # mi, tau: mi(tau) is the estimated mutual information between the time series at [0,t_total - tau] and [tau, t_total] N = len(time_series) mi = np.zeros(tau_number) tau = np.zeros(tau_number) #f = FloatProgress(min=0, max=tau_number) # instantiate the progress bar #display(f) # display the bar for i in range(0, tau_number): mi[i] = code(time_series[:N-1-i],time_series[i+1:]) tau[i]=(i+1)*dt #f.value += 1 return tau, mi  Let's try plug in x(t) of the 3D Lorenz system:\n%matplotlib inline lorenz_x = lorenz_trajectory[:,0] tau_x,mi_lorenz_x = MI_tau(lorenz_x, 0.01, MI_knn_1D) plt.plot(tau_x, mi_lorenz_x) plt.xlabel(\u0026quot;time lag\u0026quot;) plt.ylabel(\u0026quot;mutual information\u0026quot;) plt.suptitle('lorenz_x')  Text(0.5,0.98,'lorenz_x')  from scipy.signal import argrelextrema def lcmin_1_2(data, order=1): # Find the indice for the first and the second local minimum # Inputs: # data: array (n,) # order: how many points on each side to use for the comparison # Output: # lcmin_1, lcmin_2: indice for the first and the second local minimum lcmin_1 = argrelextrema(data, np.less, order=order)[0][0] lcmin_2 = argrelextrema(data, np.less, order=order)[0][1] return lcmin_1, lcmin_2  lcmin_1, lcmin_2= lcmin_1_2(mi_lorenz_x) print(lcmin_1, lcmin_2)  14 32  2. Choosing the dimension of Reconstructed Phase Space Now that we have chosen a time delay, we are ready to see how the time series look like in a d-dimensional state space with coordinates: $y(k) = [S(k), S(k+T),\u0026hellip;, S(k+(d-1)T)]$\nFirst we find the points in the reconstructed spaces:\ndef reconstruct(data, T_index, samplerate = 1, d_max = 8): # Inputs: # data: time series, (n, 1) narray # lcmin_index: the index for the time delay selected # sample: the number of data points to use for reconstruction. See Abarbanel P. 49. Oversampling needs to be avoided. # samplerate: take 1 data point for every 'samplerate' data points when reconstructing the state space # d_max: do the reconstruction for [1, d_max] dimensions # Output: # reconstru_vectors: a list of length (d_max-1) containing points in the reconstructed [2, d_max] dimensional state space sample = len(data) - (d_max-1)*T_index print(sample) reconstru_vectors = [] for d in range(1, d_max+1): reconstru_vectors_d = np.zeros((sample, d)) for i in range(0, sample): k = i*samplerate reconstru_vectors_d[i] = data[k:k+(d-1)*T_index+1:T_index] reconstru_vectors.append(reconstru_vectors_d) return reconstru_vectors  reconstru_lorenz_x_1 = reconstruct(lorenz_x, 15, d_max=10)  3065  If we try plot the lorenz x measures in 2 dimension space, we will see that the attractor is mostly unfolded but the trajectory still overlaps with itself at some point. It makes sense that the lorenz attractor can nearly be fully unfolded in dimension 2 because its fractal dimension is 2.06:\n% matplotlib inline plt.figure() plt.plot(reconstru_lorenz_x_1[1][:,0],reconstru_lorenz_x_1[1][:,1], color='blue') plt.show()  Plot the time series lorenz_x reconstructed in 3D space, using the first local minimum time delay:\ndef plot_3D(data): # plot narray data of shape (n, 3) in 3D space fig = plt.figure() axe = fig.gca(projection='3d') axe.plot(data[:,0], data[:,1],data[:,2],lw=0.5) plt.show()  plot_3D(reconstru_lorenz_x_1[2]) # vectors for reconstructed 3D space were put into index[1], for 4D space were put into [2]....  Try plotting the time series lorenz_x in 3D space using the second local minimum:\n%matplotlib inline  reconstru_lorenz_x_2 = reconstruct(lorenz_x, 30, d_max=6) plot_3D(reconstru_lorenz_x_2[2])  3050  In a chaotic system any measurement stripe will eventually spread back to the invariant measure. To avoid this kind of spreading, as can be seen in the second graph, the first local minimum would be more preferable than the second minimum.\nWe determine the minimal dimension needed to fully unfold the attractor by counting the number of global false nearest neighbors:\ndef fnn(data, reconstru, A = 2, threshold=15): # Find the percentage of false nearst neighbor in dimension d # Inputs: # data: the original time series # reconstru: vectors in reconstructed state space # d_max: do the calculation for [1, d_max-1] dimensions. # The max dimension we can get to here has to be one less than d_max for the previous step # because we have to go one dimension up to define false/truth nearest neighbors # threshold: Abarbanel says that 15 would work (Abarbanel, P. 41) # Output: the percentage of false nearest neighbor in dimensions [1, d_max] # find the nearest neighbor points in dimension [1, d_max+1], # and calculate the Euclidian distance between them and the original points d_max = len(reconstru) numerator = [] R = [] fnn_percentage = [] for d in range(1, d_max): reconstru_d = reconstru[d-1] reconstru_d_plus1 = reconstru[d] tree = ss.cKDTree(reconstru_d) ii = tree.query(reconstru_d, k = [2], p=float('inf'))[1] ii = np.squeeze(ii) reconstru_d_NN = reconstru_d[ii] # find the nearest neighbors reconstru_d_plus1_NN = reconstru_d_plus1[ii] numerator_d = abs(reconstru_d_plus1[:,-1] - reconstru_d_plus1_NN[:,-1]) R_d = np.linalg.norm(reconstru_d - reconstru_d_NN, axis = 1) # Euclidian distance fnn_1 = numerator_d / (R_d+1e-15) \u0026gt; threshold fnn_2 = numerator_d / np.std(data) \u0026gt; A fnn_d = fnn_1 | fnn_2 fnn_pct_d = np.mean(fnn_d) fnn_percentage.append(fnn_pct_d) plt.figure() plt.plot(range(1,len(fnn_percentage)+1), fnn_percentage, 'bo-') plt.title(r'FNN for time series') plt.xlabel(r'Embedding dimension $d$') plt.show() return np.array(fnn_percentage).T  def fnn_Cao(reconstru): # Find the percentage of false nearst neighbor in dimension d # Inputs: # reconstru: vectors in reconstructed state space # d_max: do the calculation for [1, d_max-2] dimensions. # The max dimension we can get to here has to be two less than d_max for the previous step # because we have to go one dimension up to define false/truth nearest neighbors, and one more up to find E1, E2 # Output: the percentage of false nearest neighbor in dimensions [1, d_max]-2 # find the nearest neighbor points in dimension [1, d_max], # and calculate the Euclidian distance between them and the original points d_max = len(reconstru) E = [] Es = [] E1 = [] E2 = [] for d in range(1, d_max): tau = 27 # reconstru_d = utils.reconstruct(mg[:-tau], d, tau) # reconstru_d_plus1 = utils.reconstruct(mg, d + 1, tau) reconstru_d = reconstru[d-1] reconstru_d_plus1 = reconstru[d] tree = ss.cKDTree(reconstru_d) dd, ii = tree.query(reconstru_d, k = [2], p=float('inf')) ii = np.squeeze(ii) dd = np.squeeze(dd) reconstru_d_NN = reconstru_d[ii] # find the nearest neighbors #reconstru_d_NN = [reconstru_d[tree.query(y, k = [3], p=float('inf'))[1]] if np.all(x==y) else x # for x, y in list(zip(reconstru_d_NN, reconstru_d))] # take the second nearest neighbor if the first nearst neighbor equals the original point reconstru_d_NN = np.vstack(reconstru_d_NN) reconstru_d_plus1_NN = reconstru_d_plus1[ii] Es_d = np.mean(abs(reconstru_d_plus1[:,-1] - reconstru_d_plus1_NN[:,-1])) R_d_plus1 = np.amax(abs(reconstru_d_plus1 - reconstru_d_plus1_NN), axis = 1) # Maximum norm a_i_d = R_d_plus1/(dd+1e-15) E_d = np.mean(a_i_d) E.append(E_d) Es.append(Es_d) for d in range(1, d_max-1): E1_d = E[d]/E[d-1] E2_d = Es[d]/Es[d-1] E1.append(E1_d) E2.append(E2_d) plt.figure() plt.plot(range(1,len(E1)+1), E1, 'bo-', label=r'$E_1(d)$') plt.plot(range(1,len(E1)+1), E2, 'go-', label=r'$E_2(d)$') plt.title(r'AFN for time series') plt.xlabel(r'Embedding dimension $d$') plt.ylabel(r'$E_1(d)$ and $E_2(d)$') plt.legend() plt.show() return np.array(E1), np.array(E2)  fnn(lorenz_x, reconstru_lorenz_x_1)  array([0.98140294, 0.04535073, 0. , 0. , 0. , 0. , 0. , 0. , 0. ])  fnn_Cao(reconstru_lorenz_x_1)  (array([1.15226236e-04, 2.92667375e-01, 9.29114296e-01, 9.43261806e-01, 9.46648770e-01, 9.28403032e-01, 9.46075408e-01, 9.81874202e-01]), array([0.06925954, 0.90807211, 1.13945518, 1.08613852, 1.0170986 , 0.94017345, 0.97299488, 1.01169999]))  This is a Jupyter Notebook I wrote in early 2018 when I first learnt about the nonlinear-time-series-analysis method of Attractor Reconstruction. Please refer to Henry Abarbanel's exceptional book [^1] for more details.\n%matplotlib inline  import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from ipywidgets import interactive from ipywidgets import FloatProgress from IPython.display import display import scipy.spatial as ss import scipy.stats as sst from scipy.special import digamma,gamma from math import log, pi, exp  0. Generate the 3D Lorenz Attractor as an example You can test out other chaotic systems simply by changing the ODE function below.\n# Define a function for generating time-seies data given ODEs def solve_ODE(time, ODE, state, parameters, dt=0.01): trajectory = np.zeros([int(time/dt), state.shape[0]]) # I used the fourth-order Runge-Kutta method def rk4(ODE, state, parameters, dt): k1 = dt * ODE(state, parameters) k2 = dt * ODE(state + 0.5 * k1, parameters) k3 = dt * ODE(state + 0.5 * k2, parameters) k4 = dt * ODE(state + k3, parameters) return state + (k1 + 2 * k2 + 2 * k3 + k4) / 6 for i in range(int(time/dt)): state = rk4(ODE, state, parameters,dt) trajectory[i,:] = state return trajectory # Define ODEs for Lorenz Attractor def lorenz_ode(state, parameters): x, y, z = state sigma, beta, rho = parameters return np.array([sigma * (y - x), x * (rho - z) - y, x * y - beta * z]) # Now putting it together, define a function for generating lorenz systems given initial state and parameters def lorenz(time, x0, y0, z0, sigma, beta, rho): state = np.array([x0,y0,z0]) parameters = np.array([sigma, beta, rho]) trajectory = solve_ODE(time, lorenz_ode, state, parameters) fig = plt.figure() axe = fig.gca(projection='3d') x, y, z = trajectory[:,0],trajectory[:,1],trajectory[:,2] lines = axe.plot(x, y, z, lw=0.5) plt.show() return trajectory  lorenz_trajectory = lorenz(2**5, -8.0, 9.0, 20.0, 10.0, 8/3.0, 28.0)  You can play with the parameters and the initial inputs:\nw = interactive(lorenz, time=(0,2**5), x0=-8, y0=9, z0=20, sigma=10, beta=4, rho=30) display(w)  Failed to display Jupyter Widget of type interactive.\n If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean that the widgets JavaScript is still loading. If this message persists, it likely means that the widgets JavaScript library is either not installed or not enabled. See the Jupyter Widgets Documentation for setup instructions.  If you're reading this message in another frontend (for example, a static rendering on GitHub or NBViewer), it may mean that your frontend doesn't currently support widgets. 1. Select the appropriate time delay for state space reconstruction We use time lagged variables to form coordinates for the reconstructed phase space. Our goal is to identify a delayed measure which would give us as much new information about the evolution of the system as possible. Fraser proposes a good delay would be when the mutual information between $s(t)$ and $s(t+T)$ reaches its first local minimum [^2]\n1.1 Mutual information estimator So we need to build a mutual information estimator. There are numerous methods aimming at correcting the bias which would arises from naively pluging in frequency distributions of the samples as the underlying probabiliy distribution. Here I choose Kraskov's K-nearest-neighbor estimator as it has been shown to be stable and less affected by parameters especially for time series from nonlinear dynamical systems [^3].\nBelow is a simple plugin code and a code based on the second algorithm proposed by the Kraskov paper.\ndef MI_plugin(x, y, base = 2): bins = np.ceil(np.log2(len(x)))+1 histgram, x_edges, y_edges = np.histogram2d(x, y, bins = bins) Pxy = histgram / float(np.sum(histgram)) Px = np.sum(Pxy, axis=1) # Get the marginal probability of x by summing over y Py = np.sum(Pxy, axis=0) # Get the marginal probability of y by summing over x PxPy = Px[:, None] * Py[None, :] non_zero = Pxy \u0026gt; 0 # Only non-zero Pxy terms contribute to the sum return np.sum(Pxy[non_zero] * np.log2(Pxy[non_zero] / PxPy[non_zero]))  def MI_knn_1D(x,y, k=3, base=2): # Input functions: # X, Y: array_like, shape (n,). Both inputs are n samples of data points with one feature # k: the number of nearest neighbour # base: log base # output function: # MI_estimate: Mutual Information estimate using the second algorithm proposed by the Kraskov paper # Kraskov, Stogbauer, and Grassberger, \u0026quot;Estimating mutual information\u0026quot;, Physical review E 69, no. 6 (2004): 066138. N = len(x) # sample size nx = np.zeros(N) ny = np.zeros(N) x = np.expand_dims(x, axis=1) y = np.expand_dims(y, axis=1) x_y = np.concatenate((x,y),axis=1) tree_xy = ss.cKDTree(x_y) tree_x = ss.cKDTree(x) tree_y = ss.cKDTree(y) for i in range(N): knn_idx = tree_xy.query(x_y[i],k+1,p=float('inf'))[1][k] knn = tree_xy.data[knn_idx] epsX = np.absolute(knn[0]-x[i]) epsY = np.absolute(knn[1]-y[i]) nx[i] = len(tree_x.query_ball_point(x[i], epsX, p=2)) ny[i] = len(tree_y.query_ball_point(y[i], epsY, p=2)) MI_estimate = (digamma(k) - 1/float(k) - (sum(list(map(digamma, nx)) + list(map(digamma, ny))) / N)+ digamma(N) ) / np.log(base) return MI_estimate  1.2 Plot MI against time delay We find mutual information as a function of time delay, and locate the time delay when mutual information reaches it first minimum.\ndef MI_tau(time_series, dt, code=MI_knn_1D, tau_number=40): # Input functions: # time_series: shape (n_samples, n_features). n_samples is the number of points in the time series, # and n_features is the dimension of the parameter space.array_like, shape (n,m). The time series to be unfolded # code: MI_knn_1D or MI_knn_multiD. For one dimensional data, both codes give same result, but MI_knn_1D runs much faster, # becuase it uses KDTree to find nearest neighbor. # tau_number: the number of time delays for which to estimate mutual information # dt: the time duration between two sample points in the time series # Output functions: # mi, tau: mi(tau) is the estimated mutual information between the time series at [0,t_total - tau] and [tau, t_total] N = len(time_series) mi = np.zeros(tau_number) tau = np.zeros(tau_number) #f = FloatProgress(min=0, max=tau_number) # instantiate the progress bar #display(f) # display the bar for i in range(0, tau_number): mi[i] = code(time_series[:N-1-i],time_series[i+1:]) tau[i]=(i+1)*dt #f.value += 1 return tau, mi  Let's try plug in x(t) of the 3D Lorenz system:\nlorenz_x = lorenz_trajectory[:,0] plt.figure() plt.plot(lorenz_x) plt.xlabel(\u0026quot;time step\u0026quot;) plt.ylabel(\u0026quot;x coordinate of the Lorenz attractor\u0026quot;)  Text(0,0.5,'x coordinate of the Lorenz attractor')  tau_x, mi_lorenz_x = MI_tau(lorenz_x, 0.01, MI_plugin) plt.plot(tau_x, mi_lorenz_x) plt.xlabel(\u0026quot;time lag\u0026quot;) plt.ylabel(\u0026quot;mutual information\u0026quot;) plt.suptitle('lorenz_x')  Text(0.5,0.98,'lorenz_x')  from scipy.signal import argrelextrema def lcmin_1_2(data, order=1): # Find the indice for the first and the second local minimum # Inputs: # data: array (n,) # order: how many points on each side to use for the comparison # Output: # lcmin_1, lcmin_2: indice for the first and the second local minimum lcmin_1 = argrelextrema(data, np.less, order=order)[0][0]+1 lcmin_2 = argrelextrema(data, np.less, order=order)[0][1]+1 return lcmin_1, lcmin_2  lcmin_1, lcmin_2= lcmin_1_2(mi_lorenz_x) print(lcmin_1, lcmin_2)  18 26  2. Choosing the dimension of Reconstructed Phase Space Now that we have chosen a time delay, we are ready to see how the time series look like in a d-dimensional state space with coordinates: $y(k) = [S(k), S(k+T),\u0026hellip;, S(k+(d-1)T)]$\nFirst we find the points in the reconstructed spaces:\ndef reconstruct(data, T_index, samplerate = 1, d_max = 8): # Inputs: # data: time series, (n, 1) narray # lcmin_index: the index for the time delay selected # sample: the number of data points to use for reconstruction. See Abarbanel P. 49. Oversampling needs to be avoided. # samplerate: take 1 data point for every 'samplerate' data points when reconstructing the state space # d_max: do the reconstruction for [1, d_max] dimensions # Output: # reconstru_vectors: a list of length (d_max-1) containing points in the reconstructed [2, d_max] dimensional state space sample = len(data) - (d_max-1)*T_index reconstru_vectors = [] for d in range(1, d_max+1): reconstru_vectors_d = np.zeros((sample, d)) for i in range(0, sample): k = i*samplerate reconstru_vectors_d[i] = data[k:k+(d-1)*T_index+1:T_index] reconstru_vectors.append(reconstru_vectors_d) return reconstru_vectors  reconstru_lorenz_x_1 = reconstruct(lorenz_x, lcmin_1, d_max=10)  If we try plot the lorenz x measures in 2 dimension space, we will see that the attractor is mostly unfolded but the trajectory still overlaps with itself at some point. It makes sense that the lorenz attractor can nearly be fully unfolded in dimension 2 because its fractal dimension is 2.06:\nplt.figure() plt.plot(reconstru_lorenz_x_1[1][:,0],reconstru_lorenz_x_1[1][:,1], color='blue') plt.show()  Plot the time series lorenz_x reconstructed in 3D space, using the first local minimum time delay:\ndef plot_3D(data): # plot narray data of shape (n, 3) in 3D space fig = plt.figure() axe = fig.gca(projection='3d') axe.plot(data[:,0], data[:,1],data[:,2],lw=0.5) plt.show()  fig = plt.figure() axe = fig.gca(projection='3d') data = reconstru_lorenz_x_1[2] axe.plot(data[:,0], data[:,1],data[:,2],lw=0.5) plt.show()  Try plotting the time series lorenz_x in 3D space using the second local minimum:\nreconstru_lorenz_x_2 = reconstruct(lorenz_x, lcmin_2, d_max=6) plot_3D(reconstru_lorenz_x_2[2])  In a chaotic system any measurement stripe will eventually spread back to the invariant measure. To avoid this kind of spreading, as can be seen in the second graph, the first local minimum would be more preferable than the second minimum.\nWe determine the minimal dimension needed to fully unfold the attractor by counting the number of global false nearest neighbors [^4]:\ndef fnn(data, reconstru, A = 2, threshold=15): # Find the percentage of false nearst neighbor in dimension d # Inputs: # data: the original time series # reconstru: vectors in reconstructed state space # d_max: do the calculation for [1, d_max-1] dimensions. # The max dimension we can get to here has to be one less than d_max for the previous step # because we have to go one dimension up to define false/truth nearest neighbors # threshold: Abarbanel says that 15 would work (Abarbanel, P. 41) # Output: the percentage of false nearest neighbor in dimensions [1, d_max] # find the nearest neighbor points in dimension [1, d_max+1], # and calculate the Euclidian distance between them and the original points d_max = len(reconstru) numerator = [] R = [] fnn_percentage = [] for d in range(1, d_max): reconstru_d = reconstru[d-1] reconstru_d_plus1 = reconstru[d] tree = ss.cKDTree(reconstru_d) ii = tree.query(reconstru_d, k = [2], p=float('inf'))[1] ii = np.squeeze(ii) reconstru_d_NN = reconstru_d[ii] # find the nearest neighbors reconstru_d_plus1_NN = reconstru_d_plus1[ii] numerator_d = abs(reconstru_d_plus1[:,-1] - reconstru_d_plus1_NN[:,-1]) R_d = np.linalg.norm(reconstru_d - reconstru_d_NN, axis = 1) # Euclidian distance fnn_1 = numerator_d / (R_d+1e-15) \u0026gt; threshold fnn_2 = numerator_d / np.std(data) \u0026gt; A fnn_d = fnn_1 | fnn_2 fnn_pct_d = np.mean(fnn_d) fnn_percentage.append(fnn_pct_d) plt.figure() plt.plot(range(1,len(fnn_percentage)+1), fnn_percentage, 'bo-') plt.title(r'FNN for time series') plt.xlabel(r'Embedding dimension $d$') plt.show() return np.array(fnn_percentage).T  Cao has proposed a revised algorithm that could more precisely determine the minimum embedding dimension [^5].\ndef fnn_Cao(reconstru): # Find the percentage of false nearst neighbor in dimension d # Inputs: # reconstru: vectors in reconstructed state space # d_max: do the calculation for [1, d_max-2] dimensions. # The max dimension we can get to here has to be two less than d_max for the previous step # because we have to go one dimension up to define false/truth nearest neighbors, and one more up to find E1, E2 # Output: the percentage of false nearest neighbor in dimensions [1, d_max]-2 # find the nearest neighbor points in dimension [1, d_max], # and calculate the Euclidian distance between them and the original points d_max = len(reconstru) E = [] Es = [] E1 = [] E2 = [] for d in range(1, d_max): tau = 27 # reconstru_d = utils.reconstruct(mg[:-tau], d, tau) # reconstru_d_plus1 = utils.reconstruct(mg, d + 1, tau) reconstru_d = reconstru[d-1] reconstru_d_plus1 = reconstru[d] tree = ss.cKDTree(reconstru_d) dd, ii = tree.query(reconstru_d, k = [2], p=float('inf')) ii = np.squeeze(ii) dd = np.squeeze(dd) reconstru_d_NN = reconstru_d[ii] # find the nearest neighbors #reconstru_d_NN = [reconstru_d[tree.query(y, k = [3], p=float('inf'))[1]] if np.all(x==y) else x # for x, y in list(zip(reconstru_d_NN, reconstru_d))] # take the second nearest neighbor if the first nearst neighbor equals the original point reconstru_d_NN = np.vstack(reconstru_d_NN) reconstru_d_plus1_NN = reconstru_d_plus1[ii] Es_d = np.mean(abs(reconstru_d_plus1[:,-1] - reconstru_d_plus1_NN[:,-1])) R_d_plus1 = np.amax(abs(reconstru_d_plus1 - reconstru_d_plus1_NN), axis = 1) # Maximum norm a_i_d = R_d_plus1/(dd+1e-15) E_d = np.mean(a_i_d) E.append(E_d) Es.append(Es_d) for d in range(1, d_max-1): E1_d = E[d]/E[d-1] E2_d = Es[d]/Es[d-1] E1.append(E1_d) E2.append(E2_d) plt.figure() plt.plot(range(1,len(E1)+1), E1, 'bo-', label=r'$E_1(d)$') plt.plot(range(1,len(E1)+1), E2, 'go-', label=r'$E_2(d)$') plt.title(r'AFN for time series') plt.xlabel(r'Embedding dimension $d$') plt.ylabel(r'$E_1(d)$ and $E_2(d)$') plt.legend() plt.show() return np.array(E1), np.array(E2)  fnn(lorenz_x, reconstru_lorenz_x_1)  array([0.97531271, 0.04542462, 0. , 0. , 0. , 0. , 0. , 0. , 0. ])  fnn_Cao(reconstru_lorenz_x_1)  (array([9.53466625e-05, 3.72059585e-01, 9.06896870e-01, 9.09639052e-01, 9.00596900e-01, 9.22524451e-01, 1.00414577e+00, 9.96374680e-01]), array([0.07351213, 0.93114608, 1.13263383, 1.02632908, 0.95937794, 0.94674472, 1.05063926, 1.01372493]))  It is clear from both algorithms that the minimum embedding dimension for the reconstructed Lorenz Attractor should be 3.\nReferences:\n[^1] Abarbanel, H. (2012). Analysis of observed chaotic data. Springer Science \u0026amp; Business Media.\n[^2] Fraser, A. M., \u0026amp; Swinney, H. L. (1986). Independent coordinates for strange attractors from mutual information. Physical review A, 33(2), 1134.\n[^3] Kraskov, Alexander, Harald StÃ¶gbauer, and Peter Grassberger. \u0026ldquo;Estimating mutual information.\u0026rdquo; Physical review E 69.6 (2004): 066138.\n[^4] Kennel, Matthew B., Reggie Brown, and Henry DI Abarbanel. \u0026ldquo;Determining embedding dimension for phase-space reconstruction using a geometrical construction.\u0026rdquo; Physical review A 45.6 (1992): 3403.\n[^5] Cao, Liangyue. \u0026ldquo;Practical method for determining the minimum embedding dimension of a scalar time series.\u0026rdquo; Physica D: Nonlinear Phenomena 110.1-2 (1997): 43-50.\n","date":1522886400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"d5a3dbace359e0db2132f105db4c08c1","permalink":"https://alicialitrtwe.github.io/codes/attractorreconstruction/","publishdate":"2018-04-05T00:00:00Z","relpermalink":"/codes/attractorreconstruction/","section":"codes","summary":"An example of nonlinear state-space reconstruction using the Lorenz attractor","tags":[],"title":"Attractor Reconstruction with Python","type":"codes"},{"authors":["Alicia Zeng"],"categories":["Demo"],"content":"Create a free website with Academic using Markdown, Jupyter, or RStudio. Choose a beautiful color theme and build anything with the Page Builder - over 40 widgets, themes, and language packs included!\nCheck out the latest demo of what you'll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\n ðŸ‘‰ Get Started ðŸ“š View the documentation ðŸ’¬ Ask a question on the forum ðŸ‘¥ Chat with the community ðŸ¦ Twitter: @source_themes @GeorgeCushen #MadeWithAcademic ðŸ’¡ Request a feature or report a bug â¬†ï¸ Updating? View the Update Guide and Release Notes â¤ Support development of Academic:  â˜•ï¸ Donate a coffee ðŸ’µ Become a backer on Patreon ðŸ–¼ï¸ Decorate your laptop or journal with an Academic sticker ðŸ‘• Wear the T-shirt ðŸ‘©â€ðŸ’» Contribute       Academic is mobile first with a responsive design to ensure that your site looks stunning on every device.   Key features:\n Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 15+ language packs including English, ä¸­æ–‡, and PortuguÃªs Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Academic comes with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the sun/moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nEcosystem  Academic Admin: An admin tool to import publications from BibTeX or import assets for an offline site Academic Scripts: Scripts to help migrate content to new versions of Academic  Install You can choose from one of the following four methods to install:\n one-click install using your web browser (recommended) install on your computer using Git with the Command Prompt/Terminal app install on your computer by downloading the ZIP files install on your computer with RStudio  Then personalize and deploy your new site.\nUpdating View the Update Guide.\nFeel free to star the project on Github to help keep track of updates.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1555459200,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"https://alicialitrtwe.github.io/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Create a beautifully simple website in under 10 minutes.","tags":["Academic"],"title":"Academic: the website builder for Hugo","type":"post"},{"authors":["Alicia Zeng"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"https://alicialitrtwe.github.io/publication/preprint/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Bird vocalizations are fundamentally high-dimensional signals with complex dynamical structure. These signals often convey biologically meaningful information that facilitates important social interactions such as territorial defense or pair bonding. Yet, many questions remain as to how birds employ their vocal organs to produce elaborate acoustic signals with specific meanings. Recent experiments have demonstrated Zebra finchesâ€™ innate sensitivity to variations in the fine structure of their vocalizations. However, the dynamical information carried by temporal fine structure has largely been neglected by prior bioacoustics studies, partly because spectral analysis - a mainstay in the birdsong community to-date - obscures the transition rules encoded in the original waveform. We adopt time-delayed embedding, a data-driven dynamical-systems approach, to discern the temporal fine structure of bird vocalizations. We show that methods from topological data analysis allow us to reconstruct and extract topological and geometrical features of the dynamical trajectories of bird vocalizations. We further demonstrate that topological descriptors of the reconstructed vocalization dynamics, serve as superior input features over traditional, spectral or temporal descriptors, enhancing the performance of a logistic regression model on pairwise classification tasks of zebra finch contact calls.","tags":null,"title":"A Topological Approach to Extract Dynamical Information from Temporal Fine Structures of Bird","type":"publication"}]